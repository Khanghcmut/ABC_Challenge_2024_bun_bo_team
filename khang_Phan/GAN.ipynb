{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7012296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd # data processing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv1D,Dropout,LSTM, Bidirectional\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "from torch.nn import Transformer\n",
    "from sklearn.preprocessing import StandardScaler #good\n",
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler\n",
    "from sklearn import metrics #accuracy measure\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92fcd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=os.listdir(\"./training_set_df_acc_win2/\")\n",
    "df=None\n",
    "for data in training_set:\n",
    "    if data.endswith('.csv'):\n",
    "        file=f\"./training_set_df_acc_win2/{data}\"\n",
    "        if df is None:\n",
    "            df=pd.read_csv(file)\n",
    "        else:\n",
    "            d=pd.read_csv(file)\n",
    "            df=pd.concat([df,d])\n",
    "X=df.drop([\"previous_label\"],axis=1)\n",
    "X_train=X\n",
    "# y=df['label']\n",
    "# X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')/255\n",
    "# # X_train = np.expand_dims(X_train, 2)\n",
    "# # X_test = np.expand_dims(X_test, 2)\n",
    "# y_train=tf.keras.utils.to_categorical(y_train)\n",
    "# y_test=tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a93699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import ELU, PReLU, LeakyReLU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81eade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimizer\n",
    "# adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "# # n_obs, feature, depth = X_train.shape\n",
    "# # Mô hình Generator\n",
    "# g = Sequential()\n",
    "# g.add(Dense(256,  activation=LeakyReLU(alpha=0.2)))\n",
    "# g.add(Dense(512, activation=LeakyReLU(alpha=0.2)))\n",
    "# g.add(Dense(1024, activation=LeakyReLU(alpha=0.2)))\n",
    "# # Vì dữ liệu ảnh MNIST đã chuẩn hóa về [0, 1] nên hàm G khi sinh ảnh ra cũng cần sinh ra ảnh có pixel value trong khoảng [0, 1] => hàm sigmoid được chọn\n",
    "# g.add(Dense(2997, activation='sigmoid'))  \n",
    "# g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# # Mô hình Discriminator\n",
    "# d = Sequential()\n",
    "# d.add(Dense(2997, activation=LeakyReLU(alpha=0.2)))\n",
    "# d.add(Dense(1024,  activation=LeakyReLU(alpha=0.2)))\n",
    "# d.add(Dropout(0.3))\n",
    "# d.add(Dense(512, activation=LeakyReLU(alpha=0.2)))\n",
    "# d.add(Dropout(0.3))\n",
    "# d.add(Dense(256, activation=LeakyReLU(alpha=0.2)))\n",
    "# d.add(Dropout(0.3))\n",
    "# # Hàm sigmoid cho bài toán binary classification \n",
    "# d.add(Dense(9, activation='sigmoid'))\n",
    "# d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# d.trainable = False\n",
    "\n",
    "# inputs = Input(shape=(2997,1))\n",
    "# hidden = g(inputs)\n",
    "# output = d(hidden)\n",
    "# gan = Model(inputs, output)\n",
    "# gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "# def plot_loss(losses):\n",
    "#     d_loss = [v[0] for v in losses[\"D\"]]\n",
    "#     g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    \n",
    "#     plt.figure(figsize=(10,8))\n",
    "#     plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "#     plt.plot(g_loss, label=\"Generator loss\")\n",
    "    \n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e344056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_dim=1\n",
    "# gloss=[]\n",
    "# dloss=[]\n",
    "# def train(epochs=1, plt_frq=1, BATCH_SIZE=2997):\n",
    "#     # Tính số lần chạy trong mỗi epoch\n",
    "#     batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "#     print('Epochs:', epochs)\n",
    "#     print('Batch size:', BATCH_SIZE)\n",
    "#     print('Batches per epoch:', batchCount)\n",
    "    \n",
    "#     for e in tqdm_notebook(range(1, epochs+1)):\n",
    "#         if e == 1 or e%plt_frq == 0:\n",
    "#             print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "#         for _ in range(batchCount):\n",
    "#             # Lấy ngẫu nhiên các ảnh từ MNIST dataset (ảnh thật)\n",
    "#             image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "#             # Sinh ra noise ngẫu nhiên\n",
    "#             print(image_batch)\n",
    "#             noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            \n",
    "#             # Dùng Generator sinh ra ảnh từ noise\n",
    "#             generated_images = g.predict(noise)\n",
    "#             X = np.concatenate((image_batch, generated_images))\n",
    "#             # Tạo label\n",
    "#             y = np.zeros(2*BATCH_SIZE)\n",
    "#             y[:BATCH_SIZE] = 0.9  # gán label bằng 0.9 cho những ảnh từ MNIST dataset và 0 cho ảnh sinh ra bởi Generator\n",
    "\n",
    "#             # Train discriminator\n",
    "#             d.trainable = True\n",
    "#             d_loss = d.fit(X, y)\n",
    "\n",
    "#             # Train generator\n",
    "#             noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "#             # Khi train Generator gán label bằng 1 cho những ảnh sinh ra bởi Generator -> cố gắng lừa Discriminator. \n",
    "#             y2 = np.ones(BATCH_SIZE)\n",
    "#             # Khi train Generator thì không cập nhật hệ số của Discriminator.\n",
    "#             d.trainable = False\n",
    "#             g_loss = gan.fit(noise, y2)\n",
    "#             print(d_loss)\n",
    "#             print(g_loss)\n",
    "# #         # Lưu loss function\n",
    "#             losses[\"D\"].append(d_loss)\n",
    "#             losses[\"G\"].append(g_loss)\n",
    "\n",
    "#         # Vẽ các số được sinh ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af2a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b73eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "# train(epochs=200, plt_frq=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1850b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3306d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024685fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_images = g.predict(X_train)\n",
    "# generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0750c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Discriminator loss: 1.7607847936451435, Generator loss: 0.6918689608573914\n",
      "Epoch 1, Discriminator loss: 0.9847675114870071, Generator loss: 0.6470180153846741\n",
      "Epoch 2, Discriminator loss: 0.9753549676388502, Generator loss: 0.5380902886390686\n",
      "Epoch 3, Discriminator loss: 1.0851581459864974, Generator loss: 0.4081955850124359\n",
      "Epoch 4, Discriminator loss: 1.292074486380443, Generator loss: 0.2622855007648468\n",
      "Epoch 5, Discriminator loss: 1.629570877092192, Generator loss: 0.1392250955104828\n",
      "Epoch 6, Discriminator loss: 2.102953805231664, Generator loss: 0.06198307126760483\n",
      "Epoch 7, Discriminator loss: 2.6809409165107354, Generator loss: 0.024449113756418228\n",
      "Epoch 8, Discriminator loss: 3.3002438923940645, Generator loss: 0.008602697402238846\n",
      "Epoch 9, Discriminator loss: 3.947879547685261, Generator loss: 0.003266444429755211\n",
      "Epoch 10, Discriminator loss: 4.657013720235227, Generator loss: 0.0011843679239973426\n",
      "Epoch 11, Discriminator loss: 5.2406061386795955, Generator loss: 0.0004434595466591418\n",
      "Epoch 12, Discriminator loss: 5.730363490159107, Generator loss: 0.00019060244085267186\n",
      "Epoch 13, Discriminator loss: 6.262873265149437, Generator loss: 8.783434896031395e-05\n",
      "Epoch 14, Discriminator loss: 6.572742887809682, Generator loss: 5.1368275308050215e-05\n",
      "Epoch 15, Discriminator loss: 6.928115861033348, Generator loss: 3.35999829985667e-05\n",
      "Epoch 16, Discriminator loss: 7.1234762382141525, Generator loss: 2.7386526198824868e-05\n",
      "Epoch 17, Discriminator loss: 7.340596213885419, Generator loss: 1.7322296116617508e-05\n",
      "Epoch 18, Discriminator loss: 7.356109028956439, Generator loss: 1.635497210372705e-05\n",
      "Epoch 19, Discriminator loss: 7.420642180554182, Generator loss: 1.3042309547017794e-05\n",
      "Epoch 20, Discriminator loss: 7.408014531882827, Generator loss: 1.3902827049605548e-05\n",
      "Epoch 21, Discriminator loss: 7.33081505518885, Generator loss: 1.3248518371256068e-05\n",
      "Epoch 22, Discriminator loss: 7.145026905674172, Generator loss: 2.624268199724611e-05\n",
      "Epoch 23, Discriminator loss: 7.023416766119908, Generator loss: 2.7891239369637333e-05\n",
      "Epoch 24, Discriminator loss: 6.813421540496051, Generator loss: 3.6457000533118844e-05\n",
      "Epoch 25, Discriminator loss: 6.521955371877425, Generator loss: 4.3757707317126915e-05\n",
      "Epoch 26, Discriminator loss: 6.339572875924205, Generator loss: 7.861941412556916e-05\n",
      "Epoch 27, Discriminator loss: 6.093167831912069, Generator loss: 0.00010599589586490765\n",
      "Epoch 28, Discriminator loss: 5.800108581050381, Generator loss: 0.00016157115169335157\n",
      "Epoch 29, Discriminator loss: 5.4927089412228725, Generator loss: 0.0002098538971040398\n",
      "Epoch 30, Discriminator loss: 5.24827661118934, Generator loss: 0.0002984680177178234\n",
      "Epoch 31, Discriminator loss: 5.018081694664943, Generator loss: 0.000444086646893993\n",
      "Epoch 32, Discriminator loss: 4.771645720702281, Generator loss: 0.0006450104992836714\n",
      "Epoch 33, Discriminator loss: 4.514464220202399, Generator loss: 0.0011131142964586616\n",
      "Epoch 34, Discriminator loss: 4.304309371203317, Generator loss: 0.0015086028724908829\n",
      "Epoch 35, Discriminator loss: 4.078248663257, Generator loss: 0.0021392020862549543\n",
      "Epoch 36, Discriminator loss: 3.915653541378333, Generator loss: 0.002881543943658471\n",
      "Epoch 37, Discriminator loss: 3.7414295460896483, Generator loss: 0.0035696420818567276\n",
      "Epoch 38, Discriminator loss: 3.687903751929298, Generator loss: 0.004306614398956299\n",
      "Epoch 39, Discriminator loss: 3.6115627153935748, Generator loss: 0.004578977823257446\n",
      "Epoch 40, Discriminator loss: 3.5926340478199563, Generator loss: 0.004606974311172962\n",
      "Epoch 41, Discriminator loss: 3.6308450004671613, Generator loss: 0.00437847850844264\n",
      "Epoch 42, Discriminator loss: 3.67705417436855, Generator loss: 0.003920287359505892\n",
      "Epoch 43, Discriminator loss: 3.7898546107417133, Generator loss: 0.00329924700781703\n",
      "Epoch 44, Discriminator loss: 3.905876805272328, Generator loss: 0.0027654876466840506\n",
      "Epoch 45, Discriminator loss: 4.016394414738443, Generator loss: 0.0022416673600673676\n",
      "Epoch 46, Discriminator loss: 4.114590582184519, Generator loss: 0.0018457869300618768\n",
      "Epoch 47, Discriminator loss: 4.192380301124103, Generator loss: 0.0016267597675323486\n",
      "Epoch 48, Discriminator loss: 4.306145514159198, Generator loss: 0.0013768093194812536\n",
      "Epoch 49, Discriminator loss: 4.369403699849045, Generator loss: 0.001350317383185029\n",
      "Epoch 50, Discriminator loss: 4.407344746258332, Generator loss: 0.001225349958986044\n",
      "Epoch 51, Discriminator loss: 4.419681602021683, Generator loss: 0.001176672289147973\n",
      "Epoch 52, Discriminator loss: 4.420994289279861, Generator loss: 0.0012606035452336073\n",
      "Epoch 53, Discriminator loss: 4.368698861940629, Generator loss: 0.0012459687422960997\n",
      "Epoch 54, Discriminator loss: 4.3655284660403595, Generator loss: 0.0013693361543118954\n",
      "Epoch 55, Discriminator loss: 4.299195328830137, Generator loss: 0.001406751456670463\n",
      "Epoch 56, Discriminator loss: 4.296634223485853, Generator loss: 0.0015271914890035987\n",
      "Epoch 57, Discriminator loss: 4.231638979269519, Generator loss: 0.0017321358900517225\n",
      "Epoch 58, Discriminator loss: 4.191958635406991, Generator loss: 0.001914425054565072\n",
      "Epoch 59, Discriminator loss: 4.153720345952934, Generator loss: 0.001903727650642395\n",
      "Epoch 60, Discriminator loss: 4.171207673336539, Generator loss: 0.00205353950150311\n",
      "Epoch 61, Discriminator loss: 4.1518603832091685, Generator loss: 0.002116785617545247\n",
      "Epoch 62, Discriminator loss: 4.160697533272469, Generator loss: 0.0021739592775702477\n",
      "Epoch 63, Discriminator loss: 4.190141893911459, Generator loss: 0.002044438384473324\n",
      "Epoch 64, Discriminator loss: 4.268644667266926, Generator loss: 0.001909941085614264\n",
      "Epoch 65, Discriminator loss: 4.292811453373361, Generator loss: 0.0017981944838538766\n",
      "Epoch 66, Discriminator loss: 4.308993389840907, Generator loss: 0.0016890116967260838\n",
      "Epoch 67, Discriminator loss: 4.425339750087005, Generator loss: 0.0015118529554456472\n",
      "Epoch 68, Discriminator loss: 4.512949499750903, Generator loss: 0.00139131851028651\n",
      "Epoch 69, Discriminator loss: 4.582298713919954, Generator loss: 0.001245836028829217\n",
      "Epoch 70, Discriminator loss: 4.6580958062641, Generator loss: 0.001148959156125784\n",
      "Epoch 71, Discriminator loss: 4.707196809877132, Generator loss: 0.0010814974084496498\n",
      "Epoch 72, Discriminator loss: 4.742444510917267, Generator loss: 0.001091963960789144\n",
      "Epoch 73, Discriminator loss: 4.785914602691264, Generator loss: 0.0010772551177069545\n",
      "Epoch 74, Discriminator loss: 4.789222734299983, Generator loss: 0.0010454370640218258\n",
      "Epoch 75, Discriminator loss: 4.79130013259055, Generator loss: 0.0011455109342932701\n",
      "Epoch 76, Discriminator loss: 4.811305863477173, Generator loss: 0.0011974219232797623\n",
      "Epoch 77, Discriminator loss: 4.807331604992214, Generator loss: 0.001278226962313056\n",
      "Epoch 78, Discriminator loss: 4.798886188702454, Generator loss: 0.0013267764588817954\n",
      "Epoch 79, Discriminator loss: 4.872986658137961, Generator loss: 0.0013411296531558037\n",
      "Epoch 80, Discriminator loss: 4.86880267446395, Generator loss: 0.0013645541621372104\n",
      "Epoch 81, Discriminator loss: 5.018414276732074, Generator loss: 0.001169330789707601\n",
      "Epoch 82, Discriminator loss: 5.150634498113504, Generator loss: 0.0011190521763637662\n",
      "Epoch 83, Discriminator loss: 5.230515803144954, Generator loss: 0.0011860938975587487\n",
      "Epoch 84, Discriminator loss: 5.252875524078263, Generator loss: 0.0013542021624743938\n",
      "Epoch 85, Discriminator loss: 5.335664571153757, Generator loss: 0.001572077046148479\n",
      "Epoch 86, Discriminator loss: 5.444897048000712, Generator loss: 0.0015893875388428569\n",
      "Epoch 87, Discriminator loss: 5.570854559788131, Generator loss: 0.0017216496635228395\n",
      "Epoch 88, Discriminator loss: 5.764554738438164, Generator loss: 0.0012344209244474769\n",
      "Epoch 89, Discriminator loss: 6.262178185294033, Generator loss: 0.0010345153277739882\n",
      "Epoch 90, Discriminator loss: 6.614426516534877, Generator loss: 0.0006936145946383476\n",
      "Epoch 91, Discriminator loss: 6.832907763920957, Generator loss: 0.0005612497916445136\n",
      "Epoch 92, Discriminator loss: 7.015873253607424, Generator loss: 0.0005419526714831591\n",
      "Epoch 93, Discriminator loss: 7.042012087062176, Generator loss: 0.0007924536475911736\n",
      "Epoch 94, Discriminator loss: 7.041603695739468, Generator loss: 0.0009525988134555519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Discriminator loss: 7.155007834851858, Generator loss: 0.0009834811789914966\n",
      "Epoch 96, Discriminator loss: 7.432646648521768, Generator loss: 0.0007478607585653663\n",
      "Epoch 97, Discriminator loss: 7.902569430807489, Generator loss: 0.0005853493930771947\n",
      "Epoch 98, Discriminator loss: 8.130012468114728, Generator loss: 0.00038663955638185143\n",
      "Epoch 99, Discriminator loss: 8.39516031643143, Generator loss: 0.00034009345108643174\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "a=list(df.columns)\n",
    "a.remove(\"previous_label\")\n",
    "a.remove(\"label\")\n",
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "def define_generator(latent_dim):\n",
    "#   \"\"\"Defines the generator model.\n",
    "\n",
    "#   Args:\n",
    "#       latent_dim: Dimensionality of the noise vector.\n",
    "\n",
    "#   Returns:\n",
    "#       A Keras model representing the generator.\n",
    "#   \"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "      keras.layers.Dense(128, activation='relu', input_shape=(latent_dim,)),\n",
    "      keras.layers.Dense(64, activation='relu'),\n",
    "      keras.layers.Dense(32, activation='relu'),\n",
    "      # Output layer with linear activation for 1D data\n",
    "      keras.layers.Dense(data_dimension, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def define_discriminator(data_dimension):\n",
    "#   \"\"\"Defines the discriminator model.\n",
    "\n",
    "#   Args:\n",
    "#       data_dimension: Dimensionality of the 1D data.\n",
    "\n",
    "#   Returns:\n",
    "#       A Keras model representing the discriminator.\n",
    "#   \"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "      keras.layers.Dense(32, activation='relu', input_shape=(data_dimension,)),\n",
    "      keras.layers.Dense(64, activation='relu'),\n",
    "      keras.layers.Dense(128, activation='relu'),\n",
    "      keras.layers.Dense(1, activation='sigmoid')  # Output layer for probability\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100  # Dimensionality of the noise vector\n",
    "data_dimension = 2996  # Adjust based on your 1D data\n",
    "epochs = 100\n",
    "batch_size = 1146\n",
    "\n",
    "# Define models\n",
    "generator = define_generator(latent_dim)\n",
    "discriminator = define_discriminator(data_dimension)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "# Combined model for training the generator\n",
    "combined_model = keras.Sequential([generator, discriminator])\n",
    "combined_model.compile(loss=['binary_crossentropy'], optimizer=tf.keras.optimizers.Adam())\n",
    "output=None\n",
    "# Real data (replace with your actual 1D data loading)\n",
    "for value in X_train['label'].unique():\n",
    "    clear_session()\n",
    "    real_data = X_train[X_train['label']==value]  # Load or generate your 1D data here\n",
    "    real_data=real_data.drop('label',axis=1)\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "      # Train discriminator on real and generated data\n",
    "      for _ in range(int(real_data.shape[0] / batch_size)):\n",
    "        noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "        fake_data = generator(noise)\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        discriminator.trainable = True\n",
    "        discriminator_loss_real = discriminator.train_on_batch(real_data, valid)\n",
    "        discriminator_loss_fake = discriminator.train_on_batch(fake_data, fake)\n",
    "        discriminator_loss = np.sum(discriminator_loss_real + discriminator_loss_fake)/2\n",
    "\n",
    "        # Train generator with discriminator frozen\n",
    "        noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        discriminator.trainable = False\n",
    "        generator_loss = combined_model.train_on_batch(noise, valid)\n",
    "\n",
    "        # Print training progress\n",
    "        print(f\"Epoch {epoch}, Discriminator loss: {discriminator_loss}, Generator loss: {generator_loss}\")\n",
    "\n",
    "    # Generate new data samples after training\n",
    "    noise = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    generated_data = generator(noise)\n",
    "    if output is None:\n",
    "        output=pd.DataFrame(generated_data, columns=a)\n",
    "        output['label']=[value]*output.shape[0]\n",
    "    else:\n",
    "        add_output=pd.DataFrame(generated_data, columns=a)\n",
    "        add_output['label']=[value]*add_output.shape[0]\n",
    "        output=pd.concat([output,add_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e7568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a7e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0592ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_elbow_shoulder_hip mean_ft</th>\n",
       "      <th>left_elbow_shoulder_hip std_ft</th>\n",
       "      <th>left_elbow_shoulder_hip max_ft</th>\n",
       "      <th>left_elbow_shoulder_hip min_ft</th>\n",
       "      <th>left_elbow_shoulder_hip var_ft</th>\n",
       "      <th>left_elbow_shoulder_hip med_ft</th>\n",
       "      <th>left_elbow_shoulder_hip sum_ft</th>\n",
       "      <th>left_elbow_shoulder_hip std</th>\n",
       "      <th>left_elbow_shoulder_hip kurtosis</th>\n",
       "      <th>left_elbow_shoulder_hip skew</th>\n",
       "      <th>...</th>\n",
       "      <th>movingcenter_y med_ft</th>\n",
       "      <th>movingcenter_y sum_ft</th>\n",
       "      <th>movingcenter_y std</th>\n",
       "      <th>movingcenter_y kurtosis</th>\n",
       "      <th>movingcenter_y skew</th>\n",
       "      <th>movingcenter_y quantile 25</th>\n",
       "      <th>movingcenter_y quantile 75</th>\n",
       "      <th>movingcenter_y RMS</th>\n",
       "      <th>movingcenter_y MAV</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023325</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>-0.102096</td>\n",
       "      <td>0.136516</td>\n",
       "      <td>-0.047850</td>\n",
       "      <td>-0.073915</td>\n",
       "      <td>-0.060884</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>-0.025914</td>\n",
       "      <td>-0.069573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106380</td>\n",
       "      <td>-0.048496</td>\n",
       "      <td>-0.038006</td>\n",
       "      <td>0.044443</td>\n",
       "      <td>0.046839</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.043331</td>\n",
       "      <td>-0.063133</td>\n",
       "      <td>-0.105253</td>\n",
       "      <td>0.173465</td>\n",
       "      <td>0.044065</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>-0.107408</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>-0.034831</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034061</td>\n",
       "      <td>-0.070323</td>\n",
       "      <td>-0.071207</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>-0.004317</td>\n",
       "      <td>0.128497</td>\n",
       "      <td>-0.083414</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039138</td>\n",
       "      <td>0.044311</td>\n",
       "      <td>-0.024225</td>\n",
       "      <td>0.085728</td>\n",
       "      <td>-0.048809</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.006657</td>\n",
       "      <td>0.046013</td>\n",
       "      <td>-0.066850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118232</td>\n",
       "      <td>-0.016115</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>-0.043966</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.039490</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.025760</td>\n",
       "      <td>0.034329</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.043654</td>\n",
       "      <td>-0.138104</td>\n",
       "      <td>0.092350</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.067266</td>\n",
       "      <td>-0.062161</td>\n",
       "      <td>-0.028048</td>\n",
       "      <td>-0.059097</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>-0.113802</td>\n",
       "      <td>-0.024812</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.084989</td>\n",
       "      <td>-0.030099</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.002312</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017171</td>\n",
       "      <td>-0.015711</td>\n",
       "      <td>-0.069084</td>\n",
       "      <td>0.099158</td>\n",
       "      <td>0.032235</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>-0.026965</td>\n",
       "      <td>-0.012148</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>-0.019743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026816</td>\n",
       "      <td>-0.061871</td>\n",
       "      <td>-0.040340</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.047301</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>2.692533</td>\n",
       "      <td>-3.303277</td>\n",
       "      <td>1.035898</td>\n",
       "      <td>-0.232399</td>\n",
       "      <td>1.868498</td>\n",
       "      <td>-2.914003</td>\n",
       "      <td>0.443995</td>\n",
       "      <td>0.351590</td>\n",
       "      <td>-2.785828</td>\n",
       "      <td>0.727185</td>\n",
       "      <td>...</td>\n",
       "      <td>3.389709</td>\n",
       "      <td>-2.421843</td>\n",
       "      <td>-0.548571</td>\n",
       "      <td>0.653123</td>\n",
       "      <td>-0.396743</td>\n",
       "      <td>2.597346</td>\n",
       "      <td>-2.682835</td>\n",
       "      <td>1.858183</td>\n",
       "      <td>-2.174753</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>3.148990</td>\n",
       "      <td>-3.908903</td>\n",
       "      <td>1.241040</td>\n",
       "      <td>-0.347734</td>\n",
       "      <td>2.314428</td>\n",
       "      <td>-3.567486</td>\n",
       "      <td>0.860128</td>\n",
       "      <td>0.305045</td>\n",
       "      <td>-3.186230</td>\n",
       "      <td>1.032997</td>\n",
       "      <td>...</td>\n",
       "      <td>3.704927</td>\n",
       "      <td>-2.851866</td>\n",
       "      <td>-0.449936</td>\n",
       "      <td>0.722055</td>\n",
       "      <td>-0.412135</td>\n",
       "      <td>3.170056</td>\n",
       "      <td>-3.093034</td>\n",
       "      <td>2.403516</td>\n",
       "      <td>-2.489592</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>2.974061</td>\n",
       "      <td>-3.857648</td>\n",
       "      <td>1.224578</td>\n",
       "      <td>-0.386632</td>\n",
       "      <td>2.345927</td>\n",
       "      <td>-3.391363</td>\n",
       "      <td>0.681273</td>\n",
       "      <td>0.321615</td>\n",
       "      <td>-2.980436</td>\n",
       "      <td>1.148912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.521381</td>\n",
       "      <td>-2.603323</td>\n",
       "      <td>-0.460132</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>-0.524313</td>\n",
       "      <td>3.210144</td>\n",
       "      <td>-2.938231</td>\n",
       "      <td>2.355963</td>\n",
       "      <td>-2.461880</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3.399573</td>\n",
       "      <td>-4.596951</td>\n",
       "      <td>1.369093</td>\n",
       "      <td>-0.621872</td>\n",
       "      <td>2.638995</td>\n",
       "      <td>-3.771714</td>\n",
       "      <td>0.783297</td>\n",
       "      <td>0.283414</td>\n",
       "      <td>-3.450206</td>\n",
       "      <td>1.361622</td>\n",
       "      <td>...</td>\n",
       "      <td>3.955267</td>\n",
       "      <td>-3.181137</td>\n",
       "      <td>-0.572529</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>-0.611598</td>\n",
       "      <td>3.621782</td>\n",
       "      <td>-3.290381</td>\n",
       "      <td>2.724145</td>\n",
       "      <td>-2.851806</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>2.920359</td>\n",
       "      <td>-3.908162</td>\n",
       "      <td>1.241816</td>\n",
       "      <td>-0.204345</td>\n",
       "      <td>2.147261</td>\n",
       "      <td>-3.509971</td>\n",
       "      <td>0.698618</td>\n",
       "      <td>0.276037</td>\n",
       "      <td>-3.063094</td>\n",
       "      <td>0.963045</td>\n",
       "      <td>...</td>\n",
       "      <td>3.694943</td>\n",
       "      <td>-2.846438</td>\n",
       "      <td>-0.520760</td>\n",
       "      <td>0.682818</td>\n",
       "      <td>-0.631985</td>\n",
       "      <td>3.245055</td>\n",
       "      <td>-3.190043</td>\n",
       "      <td>2.328654</td>\n",
       "      <td>-2.357562</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10314 rows × 2997 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      left_elbow_shoulder_hip mean_ft  left_elbow_shoulder_hip std_ft  \\\n",
       "0                            0.023325                        0.048783   \n",
       "1                           -0.043331                       -0.063133   \n",
       "2                            0.039138                        0.044311   \n",
       "3                            0.015886                        0.043654   \n",
       "4                            0.017171                       -0.015711   \n",
       "...                               ...                             ...   \n",
       "1141                         2.692533                       -3.303277   \n",
       "1142                         3.148990                       -3.908903   \n",
       "1143                         2.974061                       -3.857648   \n",
       "1144                         3.399573                       -4.596951   \n",
       "1145                         2.920359                       -3.908162   \n",
       "\n",
       "      left_elbow_shoulder_hip max_ft  left_elbow_shoulder_hip min_ft  \\\n",
       "0                          -0.102096                        0.136516   \n",
       "1                          -0.105253                        0.173465   \n",
       "2                          -0.024225                        0.085728   \n",
       "3                          -0.138104                        0.092350   \n",
       "4                          -0.069084                        0.099158   \n",
       "...                              ...                             ...   \n",
       "1141                        1.035898                       -0.232399   \n",
       "1142                        1.241040                       -0.347734   \n",
       "1143                        1.224578                       -0.386632   \n",
       "1144                        1.369093                       -0.621872   \n",
       "1145                        1.241816                       -0.204345   \n",
       "\n",
       "      left_elbow_shoulder_hip var_ft  left_elbow_shoulder_hip med_ft  \\\n",
       "0                          -0.047850                       -0.073915   \n",
       "1                           0.044065                        0.031890   \n",
       "2                          -0.048809                       -0.012988   \n",
       "3                          -0.000107                       -0.067266   \n",
       "4                           0.032235                        0.028817   \n",
       "...                              ...                             ...   \n",
       "1141                        1.868498                       -2.914003   \n",
       "1142                        2.314428                       -3.567486   \n",
       "1143                        2.345927                       -3.391363   \n",
       "1144                        2.638995                       -3.771714   \n",
       "1145                        2.147261                       -3.509971   \n",
       "\n",
       "      left_elbow_shoulder_hip sum_ft  left_elbow_shoulder_hip std  \\\n",
       "0                          -0.060884                    -0.008066   \n",
       "1                          -0.107408                     0.004244   \n",
       "2                          -0.003931                    -0.006657   \n",
       "3                          -0.062161                    -0.028048   \n",
       "4                          -0.026965                    -0.012148   \n",
       "...                              ...                          ...   \n",
       "1141                        0.443995                     0.351590   \n",
       "1142                        0.860128                     0.305045   \n",
       "1143                        0.681273                     0.321615   \n",
       "1144                        0.783297                     0.283414   \n",
       "1145                        0.698618                     0.276037   \n",
       "\n",
       "      left_elbow_shoulder_hip kurtosis  left_elbow_shoulder_hip skew  ...  \\\n",
       "0                            -0.025914                     -0.069573  ...   \n",
       "1                            -0.034831                      0.030575  ...   \n",
       "2                             0.046013                     -0.066850  ...   \n",
       "3                            -0.059097                      0.005874  ...   \n",
       "4                             0.023786                     -0.019743  ...   \n",
       "...                                ...                           ...  ...   \n",
       "1141                         -2.785828                      0.727185  ...   \n",
       "1142                         -3.186230                      1.032997  ...   \n",
       "1143                         -2.980436                      1.148912  ...   \n",
       "1144                         -3.450206                      1.361622  ...   \n",
       "1145                         -3.063094                      0.963045  ...   \n",
       "\n",
       "      movingcenter_y med_ft  movingcenter_y sum_ft  movingcenter_y std  \\\n",
       "0                  0.106380              -0.048496           -0.038006   \n",
       "1                 -0.034061              -0.070323           -0.071207   \n",
       "2                  0.118232              -0.016115            0.003171   \n",
       "3                  0.016607              -0.113802           -0.024812   \n",
       "4                 -0.026816              -0.061871           -0.040340   \n",
       "...                     ...                    ...                 ...   \n",
       "1141               3.389709              -2.421843           -0.548571   \n",
       "1142               3.704927              -2.851866           -0.449936   \n",
       "1143               3.521381              -2.603323           -0.460132   \n",
       "1144               3.955267              -3.181137           -0.572529   \n",
       "1145               3.694943              -2.846438           -0.520760   \n",
       "\n",
       "      movingcenter_y kurtosis  movingcenter_y skew  \\\n",
       "0                    0.044443             0.046839   \n",
       "1                    0.034562            -0.004317   \n",
       "2                   -0.043966             0.058107   \n",
       "3                    0.040384             0.008616   \n",
       "4                   -0.006339             0.013629   \n",
       "...                       ...                  ...   \n",
       "1141                 0.653123            -0.396743   \n",
       "1142                 0.722055            -0.412135   \n",
       "1143                 0.727969            -0.524313   \n",
       "1144                 0.904297            -0.611598   \n",
       "1145                 0.682818            -0.631985   \n",
       "\n",
       "      movingcenter_y quantile 25  movingcenter_y quantile 75  \\\n",
       "0                       0.028132                   -0.007854   \n",
       "1                       0.128497                   -0.083414   \n",
       "2                       0.039490                    0.011036   \n",
       "3                       0.084989                   -0.030099   \n",
       "4                       0.047301                    0.032353   \n",
       "...                          ...                         ...   \n",
       "1141                    2.597346                   -2.682835   \n",
       "1142                    3.170056                   -3.093034   \n",
       "1143                    3.210144                   -2.938231   \n",
       "1144                    3.621782                   -3.290381   \n",
       "1145                    3.245055                   -3.190043   \n",
       "\n",
       "      movingcenter_y RMS  movingcenter_y MAV  label  \n",
       "0               0.074282            0.059056      8  \n",
       "1               0.012322           -0.000707      8  \n",
       "2               0.025760            0.034329      8  \n",
       "3               0.051068           -0.002312      8  \n",
       "4               0.017158            0.018240      8  \n",
       "...                  ...                 ...    ...  \n",
       "1141            1.858183           -2.174753      7  \n",
       "1142            2.403516           -2.489592      7  \n",
       "1143            2.355963           -2.461880      7  \n",
       "1144            2.724145           -2.851806      7  \n",
       "1145            2.328654           -2.357562      7  \n",
       "\n",
       "[10314 rows x 2997 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba017dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"./gan_win2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded0e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb89186",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SHAP analysis\n",
    "# feature_names = X_train.columns\n",
    "\n",
    "\n",
    "# rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "# vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "# shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "#                                   columns=['col_name','feature_importance_vals'])\n",
    "# shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "#                                ascending=False, inplace=True)\n",
    "# shap_importance.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
