{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd # data processing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv1D,Dropout,LSTM, Bidirectional\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "from torch.nn import Transformer\n",
    "from sklearn.preprocessing import StandardScaler #bad\n",
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacffe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv1D, Conv1DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Define the generator model\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=100, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(2997, activation='tanh'))\n",
    "    model.add(Reshape((1, 2997)))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=5, strides=2, input_shape=(1, 2997), padding='same', activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define the DCGAN model\n",
    "def make_dcgan_model():\n",
    "    generator = make_generator_model()\n",
    "    discriminator = make_discriminator_model()\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    gan_input = Input(shape=(2297,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan, generator, discriminator\n",
    "\n",
    "# Create the DCGAN model\n",
    "gan, generator, discriminator = make_dcgan_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=os.listdir(\"./training_set_df_acc/\")\n",
    "df=None\n",
    "for data in training_set:\n",
    "    if data.endswith('.csv'):\n",
    "        file=f\"./training_set_df_acc/{data}\"\n",
    "        if df is None:\n",
    "            df=pd.read_csv(file)\n",
    "        else:\n",
    "            d=pd.read_csv(file)\n",
    "            df=pd.concat([df,d])\n",
    "X=df.drop([\"previous_label\"],axis=1)\n",
    "X_train=X\n",
    "for value in X_train['label'].unique():\n",
    "    training=\n",
    "    gan.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf336ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9234355f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219d3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693eb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12872560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a147a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a9490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1172f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
